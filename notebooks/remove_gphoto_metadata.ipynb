{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why\n",
    "As part of the project of De-Googling myself I had to [export](https://takeout.google.com/settings/takeout?pli=1) my memories from Google Photos and load it back to my Synology. However, exports have:\n",
    "1. metadata that I might want to drop\n",
    "1. inconsistent names (my library spans many smartphone generations with Android and iOS)\n",
    "1. directories have weird names (a consequence of file segmentation and a 2GB download limit)\n",
    "Basically I want to automate this with a script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    |-- basedir\n",
    "    |   |-- 2016-01-01\n",
    "    |   |   |-- filename-1.jpg\n",
    "    |   |   |-- filename-2.jpg.json\n",
    "    |   |   |-- filename-3.jpg\n",
    "    |   |   |-- filename-3.jpg.json\n",
    "    |   |-- 2016-01-02\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the export (extracted archive)\n",
    "base_path = f'/Users/lorismarini/Desktop/google-photos-elisa-takeout'\n",
    "\n",
    "# Directory for the output (files in folders)\n",
    "output_path = f'/Users/lorismarini/Desktop/google-photos-elisa-to-synology'\n",
    "\n",
    "# Search for all files recursively\n",
    "files_all = [name for name in glob.glob(f\"{base_path}/**/*.*\", recursive=True)]\n",
    "\n",
    "# Filter out all json files\n",
    "files_keep = [name for name in files_all if not name.endswith(\".json\")]\n",
    "\n",
    "# Extract basenames of files to keep\n",
    "basenames_keep = [os.path.basename(f) for f in files_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dataframe\n",
    "df = pd.DataFrame({\"abspath_src\":files_keep, \"basenames\":basenames_keep})\n",
    "\n",
    "# Determine if the first two characters of the basename are letters\n",
    "df[\"is_alpha\"] = df[\"basenames\"].apply(lambda x: x[:2].isalpha())\n",
    "\n",
    "# --------------- PARSE TIME --------------------\n",
    "\n",
    "def timestring_starts_number(n):\n",
    "    \"\"\"Parse time for filenames starting with numbers\n",
    "    \"\"\"\n",
    "    return n.split(\"_\")[0]\n",
    "\n",
    "def timestring_starts_alpha(n):\n",
    "    \"\"\"Parse time for filenames starting with letters\n",
    "    \"\"\"\n",
    "    if \"-\" in n:\n",
    "        parts = n.split(\"-\")\n",
    "    elif \"_\" in n:\n",
    "        parts = n.split(\"_\")\n",
    "    else:\n",
    "        return \"\"\n",
    "    if len(parts)>1:\n",
    "        return parts[1]\n",
    "    else:\n",
    "        return parts[0]\n",
    "    \n",
    "# Parse for is_alpha = True\n",
    "alpha = df[\"is_alpha\"]==True\n",
    "df.loc[alpha, \"time\"] = pd.to_datetime(df.loc[alpha, \"basenames\"].apply(timestring_starts_alpha), errors=\"coerce\")\n",
    "\n",
    "# Parse for is_alpha = False\n",
    "where = df[\"is_alpha\"]==False\n",
    "df.loc[where, \"time\"] = pd.to_datetime(df.loc[where, \"basenames\"].apply(timestring_starts_number), errors=\"coerce\")\n",
    "\n",
    "# Folder name from datetime\n",
    "df[\"basedir_dest\"] = df[\"time\"].dt.date.astype(str)\n",
    "\n",
    "# Dirname destination path\n",
    "df[\"dirname_dest\"] = df[\"basedir_dest\"].apply(lambda x: os.path.join(output_path, x))\n",
    "\n",
    "# Abspath destination\n",
    "df[\"abspath_dest\"] = df[\"dirname_dest\"] + \"/\" + df[\"basenames\"]\n",
    "\n",
    "files_to_move = df[~df[\"time\"].isnull()].shape[0]\n",
    "files_ignored = df[df[\"time\"].isnull()].shape[0]\n",
    "\n",
    "print(f\"{files_to_move} files to move...\")\n",
    "print(f\"{files_ignored} files ingored...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tomove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tomove = df[~df[\"time\"].isnull()]\n",
    "\n",
    "# Create destination directories if they don't exist\n",
    "dirname_dest_unique = df_tomove[\"dirname_dest\"].unique()\n",
    "_ = [os.makedirs(d) for d in dirname_dest_unique]\n",
    "print(f\"{len(dirname_dest_unique)} directories consolidated...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moved = 0\n",
    "already_moved = 0\n",
    "lost = 0\n",
    "for i in df_tomove.index:\n",
    "\n",
    "    # Move file\n",
    "    src = df_tomove.loc[i,\"abspath_src\"]\n",
    "    dst = df_tomove.loc[i,\"abspath_dest\"]\n",
    "    \n",
    "    if os.path.exists(src):\n",
    "        # Move file\n",
    "        shutil.move(src, dst)\n",
    "        moved += 1\n",
    "    elif os.path.exists(dst):\n",
    "        # File already moved skip\n",
    "        already_moved += 1\n",
    "        pass\n",
    "    else:\n",
    "        lost += 1\n",
    "        print(f\"DATA INTEGRITY ERROR, File not found in src {src} or dst {dst}!\")\n",
    "        \n",
    "print(f\"{moved} moved\")\n",
    "print(f\"{already_moved} already moved\")\n",
    "print(f\"{lost} lost\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
